{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6xoLDtS_6Df1"
   },
   "source": [
    "# ElasticSearch Amazon SageMaker Blog\n",
    "# Loading an embedding from Hugging Face into Elasticsearch\n",
    "\n",
    "This code will show you how to load a supported embedding model from Hugging Face into an elasticsearch cluster in [Elastic Cloud](https://cloud.elastic.co/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DgxCKQS7mCZw"
   },
   "source": [
    "# Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ly1f1P-l9ri8"
   },
   "source": [
    "## Install and import required python libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MJAb_8zlPFhQ"
   },
   "source": [
    "Elastic uses the [eland python library](https://github.com/elastic/eland) to download modesl from Hugging Face hub and load them into elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "rUedSzQW9FIF",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "triton 2.0.0 requires cmake, which is not installed.\n",
      "triton 2.0.0 requires lit, which is not installed.\n",
      "torchdata 0.6.0 requires torch>1.13, but you have torch 1.11.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip -q install eland elasticsearch sentence_transformers transformers torch==1.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "wyUZXUi4RWWL",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from eland.ml.pytorch import PyTorchModel\n",
    "from eland.ml.pytorch.transformers import TransformerModel\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.client import MlClient\n",
    "\n",
    "import getpass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r7nMIbHke37Q"
   },
   "source": [
    "## Configure elasticsearch authentication.\n",
    "The recommended authentication approach is using the [Elastic Cloud ID](https://www.elastic.co/guide/en/cloud/current/ec-cloud-id.html) and a [cluster level API key](https://www.elastic.co/guide/en/kibana/current/api-keys.html)\n",
    "\n",
    "You can use any method you wish to set the required credentials. We are using getpass in this example to prompt for credentials to avoide storing them in github."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "SSGgYHome69o",
    "tags": []
   },
   "outputs": [],
   "source": [
    "es_cloud_id = getpass.getpass('Enter Elastic Cloud ID:  ')\n",
    "es_user = getpass.getpass('Enter cluster username:  ')\n",
    "es_pass = getpass.getpass('Enter cluster password:  ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jL4VDnVp96lf"
   },
   "source": [
    "## Connect to Elastic Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "I8mVJkKmetXo",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'name': 'instance-0000000000', 'cluster_name': 'e676bcbabc614a61b038a91a02b2c6dc', 'cluster_uuid': 'AlptJ-AASPGPzHy33ahRMQ', 'version': {'number': '8.9.0', 'build_flavor': 'default', 'build_type': 'docker', 'build_hash': '8aa461beb06aa0417a231c345a1b8c38fb498a0d', 'build_date': '2023-07-19T14:43:58.555259655Z', 'build_snapshot': False, 'lucene_version': '9.7.0', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#es = Elasticsearch(cloud_id=es_cloud_id,\n",
    "#                   api_key=(es_api_id, es_api_key)\n",
    "#                   )\n",
    "es = Elasticsearch(cloud_id=es_cloud_id,\n",
    "                   basic_auth=(es_user, es_pass)\n",
    "                   )\n",
    "es.info() # should return cluster info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uBMWHj-ZmtvE"
   },
   "source": [
    "# Load the model From Hugging Face into Elasticsearch\n",
    "Here we specify the model id from Hugging Face. The easiest way to get this id is clicking the copy the model name icon next to the name on the model page.\n",
    "\n",
    "When calling `TransformerModel` you specify the HF model id and the task type. You can try specifying `auto` and eland will attempt to determine the correct type from info in the model config. This is not always possible so a list of specific `task_type` values can be viewed in the following code:\n",
    "[Supported values](https://github.com/elastic/eland/blob/15a300728876022b206161d71055c67b500a0192/eland/ml/pytorch/transformers.py#*L41*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "zPV3oFsKiYFL",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37a89c1c304a460885bc27d4f7d80a51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/105 [00:00<?, ? parts/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set the model name from Hugging Face and task type\n",
    "# hf_model_id='sentence-transformers/all-distilroberta-v1'\n",
    "hf_model_id = 'BAAI/bge-base-en'\n",
    "tm = TransformerModel(hf_model_id, \"text_embedding\")\n",
    "\n",
    "#set the modelID as it is named in Elasticsearch\n",
    "es_model_id = tm.elasticsearch_model_id()\n",
    "\n",
    "# Download the model from Hugging Face\n",
    "tmp_path = \"models\"\n",
    "Path(tmp_path).mkdir(parents=True, exist_ok=True)\n",
    "model_path, config, vocab_path = tm.save(tmp_path)\n",
    "\n",
    "# Load the model into Elasticsearch\n",
    "ptm = PyTorchModel(es, es_model_id)\n",
    "ptm.import_model(model_path=model_path, config_path=None, vocab_path=vocab_path, config=config) # ETA 7:30, also too big for \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4UYSzFp3vHdB"
   },
   "source": [
    "# Starting the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wQwfozwznK4Y"
   },
   "source": [
    "## View information about the model\n",
    "This is not required but can be handy to get a model overivew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "b4Wv8EJvpfZI",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'count': 1,\n",
       " 'trained_model_configs': [{'model_id': 'baai__bge-base-en',\n",
       "   'model_type': 'pytorch',\n",
       "   'created_by': 'api_user',\n",
       "   'version': '8.9.0',\n",
       "   'create_time': 1691986436892,\n",
       "   'model_size_bytes': 0,\n",
       "   'estimated_operations': 0,\n",
       "   'license_level': 'platinum',\n",
       "   'description': \"Model BAAI/bge-base-en for task type 'text_embedding'\",\n",
       "   'tags': [],\n",
       "   'input': {'field_names': ['text_field']},\n",
       "   'inference_config': {'text_embedding': {'vocabulary': {'index': '.ml-inference-native-000001'},\n",
       "     'tokenization': {'bert': {'do_lower_case': True,\n",
       "       'with_special_tokens': True,\n",
       "       'max_sequence_length': 512,\n",
       "       'truncate': 'first',\n",
       "       'span': -1}}}},\n",
       "   'location': {'index': {'name': '.ml-inference-native-000001'}}}]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List the in elasticsearch\n",
    "m = MlClient.get_trained_models(es, model_id=es_model_id)\n",
    "m.body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oMGw3sk-pbaN"
   },
   "source": [
    "## Deploy the model\n",
    "This will load the model on the ML nodes and start the process(es) making it available for the NLP task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "w5muJ1rLqvUW",
    "tags": []
   },
   "outputs": [
    {
     "ename": "ConnectionTimeout",
     "evalue": "Connection timed out",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionTimeout\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[43mMlClient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_trained_model_deployment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mes_model_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m s\u001b[38;5;241m.\u001b[39mbody\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/elasticsearch/_sync/client/utils.py:414\u001b[0m, in \u001b[0;36m_rewrite_parameters.<locals>.wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m    412\u001b[0m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 414\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapi\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/elasticsearch/_sync/client/ml.py:3791\u001b[0m, in \u001b[0;36mMlClient.start_trained_model_deployment\u001b[0;34m(self, model_id, cache_size, error_trace, filter_path, human, number_of_allocations, pretty, priority, queue_capacity, threads_per_allocation, timeout, wait_for)\u001b[0m\n\u001b[1;32m   3789\u001b[0m     __query[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwait_for\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m wait_for\n\u001b[1;32m   3790\u001b[0m __headers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccept\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m-> 3791\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperform_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[return-value]\u001b[39;49;00m\n\u001b[1;32m   3792\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m__path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m__query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m__headers\u001b[49m\n\u001b[1;32m   3793\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/elasticsearch/_sync/client/_base.py:285\u001b[0m, in \u001b[0;36mBaseClient.perform_request\u001b[0;34m(self, method, path, params, headers, body)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    283\u001b[0m     target \u001b[38;5;241m=\u001b[39m path\n\u001b[0;32m--> 285\u001b[0m meta, resp_body \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperform_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_max_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry_on_status\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_on_status\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry_on_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_on_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_meta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client_meta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;66;03m# HEAD with a 404 is returned as a normal response\u001b[39;00m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;66;03m# since this is used as an 'exists' functionality.\u001b[39;00m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHEAD\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m meta\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m404\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m meta\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m299\u001b[39m\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    305\u001b[0m     )\n\u001b[1;32m    306\u001b[0m ):\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/elastic_transport/_transport.py:329\u001b[0m, in \u001b[0;36mTransport.perform_request\u001b[0;34m(self, method, target, body, headers, max_retries, retry_on_status, retry_on_timeout, request_timeout, client_meta)\u001b[0m\n\u001b[1;32m    327\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 329\u001b[0m     meta, raw_data \u001b[38;5;241m=\u001b[39m \u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperform_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    336\u001b[0m     _logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    337\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m [status:\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m duration:\u001b[39m\u001b[38;5;132;01m%.3f\u001b[39;00m\u001b[38;5;124ms]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    338\u001b[0m         \u001b[38;5;241m%\u001b[39m (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    344\u001b[0m         )\n\u001b[1;32m    345\u001b[0m     )\n\u001b[1;32m    347\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHEAD\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/elastic_transport/_node/_http_urllib3.py:199\u001b[0m, in \u001b[0;36mUrllib3HttpNode.perform_request\u001b[0;34m(self, method, target, body, headers, request_timeout)\u001b[0m\n\u001b[1;32m    191\u001b[0m         err \u001b[38;5;241m=\u001b[39m \u001b[38;5;167;01mConnectionError\u001b[39;00m(\u001b[38;5;28mstr\u001b[39m(e), errors\u001b[38;5;241m=\u001b[39m(e,))\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_request(\n\u001b[1;32m    193\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    194\u001b[0m         target\u001b[38;5;241m=\u001b[39mtarget,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    197\u001b[0m         exception\u001b[38;5;241m=\u001b[39merr,\n\u001b[1;32m    198\u001b[0m     )\n\u001b[0;32m--> 199\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    201\u001b[0m meta \u001b[38;5;241m=\u001b[39m ApiResponseMeta(\n\u001b[1;32m    202\u001b[0m     node\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig,\n\u001b[1;32m    203\u001b[0m     duration\u001b[38;5;241m=\u001b[39mduration,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    206\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresponse_headers,\n\u001b[1;32m    207\u001b[0m )\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_request(\n\u001b[1;32m    209\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    210\u001b[0m     target\u001b[38;5;241m=\u001b[39mtarget,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    214\u001b[0m     response\u001b[38;5;241m=\u001b[39mdata,\n\u001b[1;32m    215\u001b[0m )\n",
      "\u001b[0;31mConnectionTimeout\u001b[0m: Connection timed out"
     ]
    }
   ],
   "source": [
    "s = MlClient.start_trained_model_deployment(es, model_id=es_model_id)\n",
    "s.body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZytlELrsnn_O"
   },
   "source": [
    "## Verify the model started without issue\n",
    "Should output -> {'routing_state': 'started'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "ZaQUUWe0Hxwz",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'routing_state': 'started'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = MlClient.get_trained_models_stats(es, model_id=es_model_id)\n",
    "stats.body['trained_model_stats'][0]['deployment_stats']['nodes'][0]['routing_state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
